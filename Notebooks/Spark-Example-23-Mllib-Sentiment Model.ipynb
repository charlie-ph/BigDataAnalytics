{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis model using PySpark\n",
    "The task is to create a sentiment analysis model using PySpark that can classify movie reviews as either positive or negative. The input data consists of a large dataset of movie reviews that have been labeled with a sentiment score (positive or negative). The goal is to build a binary classification model that can accurately predict the sentiment of a new movie review that it has not seen before. \n",
    "\n",
    "The sentiment analysis model will use natural language processing (NLP) techniques to preprocess the text data, including tokenization, stopword removal, count vectorization, and TF-IDF. It will then use different machine learning algorithms, such as logistic regression, SVM, or a multilayer perceptron, to train a binary classifier on the preprocessed text features. The model will be evaluated using metrics precision, recall, F1 score, and confusion matrix. \n",
    "\n",
    "In the end, we show how feature selection techniques such as Chi-Square can be included in the preprocessing pipeline, and we build a logistic regression model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext(\"local[*]\")\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                text|sentiment|\n",
      "+--------------------+---------+\n",
      "|One of the other ...| positive|\n",
      "|A wonderful littl...| positive|\n",
      "|I thought this wa...| positive|\n",
      "|Basically there's...| negative|\n",
      "|Petter Mattei's L...| positive|\n",
      "|Probably my all-t...| positive|\n",
      "|I sure would like...| positive|\n",
      "|This show was an ...| negative|\n",
      "|Encouraged by the...| negative|\n",
      "|If you like origi...| positive|\n",
      "+--------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tFile=\"data\\IMDB Dataset.csv.bz2\"\n",
    "df0 = spark.read.csv(tFile,header=True)\n",
    "df0.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample the data for faster model training (use the full dataset in reality)\n",
    "df0 = df0.sample(0.25, seed=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment to numbers positive =1, negative =0\n",
    "df0 = df0.withColumn(\"label\", F.when(F.col(\"sentiment\")==\"positive\",1).otherwise(0)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>text_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12643</th>\n",
       "      <td>To be hones, I used to like this show and watc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>hones  used  like this show and watch  regul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12644</th>\n",
       "      <td>This movie is a disgrace to the Major League F...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>This movie   disgrace  the Major League Franch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12645</th>\n",
       "      <td>John Garfield plays a Marine who is blinded by...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>John Garfield plays  Marine who  blinded   gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12646</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12647</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>going  have  disagree with the previous comme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment  label   \n",
       "12643  To be hones, I used to like this show and watc...  negative      0  \\\n",
       "12644  This movie is a disgrace to the Major League F...  negative      0   \n",
       "12645  John Garfield plays a Marine who is blinded by...  positive      1   \n",
       "12646  Bad plot, bad dialogue, bad acting, idiotic di...  negative      0   \n",
       "12647  I'm going to have to disagree with the previou...  negative      0   \n",
       "\n",
       "                                                  text_c  \n",
       "12643    hones  used  like this show and watch  regul...  \n",
       "12644  This movie   disgrace  the Major League Franch...  \n",
       "12645  John Garfield plays  Marine who  blinded   gre...  \n",
       "12646  Bad plot bad dialogue bad acting idiotic direc...  \n",
       "12647   going  have  disagree with the previous comme...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove html tags from text\n",
    "df0 = df0.withColumn(\"text_c\", F.regexp_replace(F.col(\"text\"), r'<[^>]+>', \"\"));\n",
    "# Remove non-letters\n",
    "df0 = df0.withColumn(\"text_c\", F.regexp_replace(\"text_c\", r\"[^a-zA-Z ]\", \"\"))\n",
    "# Remove words 1, 2 char\n",
    "df0 = df0.withColumn(\"text_c\", F.regexp_replace(\"text_c\", r\"\\b\\w{1,2}\\b\", \"\"))\n",
    "df0.toPandas().tail(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization (optional)\n",
    "Lemmatization is the process of reducing a word to its base or root form, which is also known as a lemma. The purpose of lemmatization is to simplify text and make it easier to analyze by grouping together different forms of the same word. For example, the words \"running,\" \"ran,\" and \"runs\" can all be reduced to the base form \"run\" through lemmatization. \n",
    "\n",
    "However, lemmatization can be a **time-consuming operation**, especially when dealing with large amounts of text data. This is because the process involves analyzing each word in a text and identifying its base form. It also requires a comprehensive understanding of the grammatical rules of a language to accurately identify the correct lemma for each word.\n",
    "\n",
    "Despite its time-consuming nature, lemmatization can be a powerful tool in natural language processing and text analysis. It can help with tasks such as sentiment analysis, topic modeling, and text classification. When using lemmatization, it's important to use it carefully and correctly to ensure that the text is properly processed and analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>text_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12643</th>\n",
       "      <td>To be hones, I used to like this show and watc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>hone   use   like this show and watch   reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12644</th>\n",
       "      <td>This movie is a disgrace to the Major League F...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>this movie    disgrace   the Major League Fran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12645</th>\n",
       "      <td>John Garfield plays a Marine who is blinded by...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>John Garfield play   Marine who   blind    gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12646</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>bad plot bad dialogue bad act idiotic direct t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12647</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>go   have   disagree with the previous comme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment  label   \n",
       "12643  To be hones, I used to like this show and watc...  negative      0  \\\n",
       "12644  This movie is a disgrace to the Major League F...  negative      0   \n",
       "12645  John Garfield plays a Marine who is blinded by...  positive      1   \n",
       "12646  Bad plot, bad dialogue, bad acting, idiotic di...  negative      0   \n",
       "12647  I'm going to have to disagree with the previou...  negative      0   \n",
       "\n",
       "                                                  text_c  \n",
       "12643     hone   use   like this show and watch   reg...  \n",
       "12644  this movie    disgrace   the Major League Fran...  \n",
       "12645  John Garfield play   Marine who   blind    gre...  \n",
       "12646  bad plot bad dialogue bad act idiotic direct t...  \n",
       "12647    go   have   disagree with the previous comme...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Define a function to apply the lemmatizer to a text\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "# Define a UDF to apply the lemmatizer to a column\n",
    "lemmatize_udf = udf(lemmatize_text, StringType())\n",
    "\n",
    "# Apply the UDF to a DataFrame column\n",
    "df0 = df0.withColumn(\"text_c\", lemmatize_udf(df0[\"text_c\"]))\n",
    "\n",
    "# Caching must be used !!!!!!\n",
    "df0 = df0.cache()\n",
    "df0.toPandas().tail(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the text to training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1| 5016|\n",
      "|    0| 5138|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data in train and test (80%-20%)\n",
    "df, test = df0.randomSplit(weights=[0.8,0.2], seed=200)\n",
    "df.groupBy(\"label\").count().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign weights to classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5060074847350797 0.4939925152649202\n"
     ]
    }
   ],
   "source": [
    "# Create a weight of each class\n",
    "from pyspark.sql import functions as F\n",
    "p_weight = df.filter('label == 1').count()/ df.count()\n",
    "n_weight = df.filter('label == 0').count()/ df.count()\n",
    "print(n_weight, p_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+--------------------+------------------+\n",
      "|                text|sentiment|label|              text_c|            weight|\n",
      "+--------------------+---------+-----+--------------------+------------------+\n",
      "| Så som i himmele...| positive|    1|   som   himmelen...|0.5060074847350797|\n",
      "| While sporadical...| negative|    0|  while sporadica...|0.4939925152649202|\n",
      "|'Blue Desert' may...| negative|    0|Blue Desert may h...|0.4939925152649202|\n",
      "|'Checking Out' is...| positive|    1|check out    extr...|0.5060074847350797|\n",
      "|'Presque Rien' ('...| positive|    1|presque Rien come...|0.5060074847350797|\n",
      "+--------------------+---------+-----+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"weight\", F.when(F.col(\"label\")==1,n_weight).otherwise(p_weight))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline\n",
    "Pipelines in Spark are a powerful tool for data processing and analysis, as they enable the creation of complex data workflows that can be executed efficiently on distributed computing systems. They also simplify the data processing and analysis tasks, as they enable the chaining of multiple stages into a single workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the review text\n",
    "tokenizer = Tokenizer(inputCol=\"text_c\", outputCol=\"words\",)\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "# Create a count vectorizer\n",
    "countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"rawFeatures\", vocabSize=1000)\n",
    "# Calculate the TF-IDF\n",
    "idf = IDF(inputCol=countVectorizer.getOutputCol(), outputCol=\"featuresIDF\")\n",
    "# Crate a preprocessing pipeline with 4 stages\n",
    "pipeline_p = Pipeline(stages=[tokenizer,remover, countVectorizer, idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the data preprocessing model\n",
    "data_model = pipeline_p.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>text_c</th>\n",
       "      <th>weight</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>rawFeatures</th>\n",
       "      <th>featuresIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Så som i himmelen  .. as above so below.. tha...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>som   himmelen     above   below that very ...</td>\n",
       "      <td>0.506007</td>\n",
       "      <td>[, , , som, , , himmelen, , , , , above, , , b...</td>\n",
       "      <td>[, , , som, , , himmelen, , , , , , , special,...</td>\n",
       "      <td>(77.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>(0.015166436921203202, 0.0, 2.147722756669075,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>While sporadically engrossing (including a fe...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>while sporadically engross include   few eff...</td>\n",
       "      <td>0.493993</td>\n",
       "      <td>[, , while, sporadically, engross, include, , ...</td>\n",
       "      <td>[, , sporadically, engross, include, , , effec...</td>\n",
       "      <td>(72.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0,...</td>\n",
       "      <td>(0.014181603354891307, 0.0, 1.6107920675018061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Blue Desert' may have had the potential to be...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>Blue Desert may have have the potential    eve...</td>\n",
       "      <td>0.493993</td>\n",
       "      <td>[blue, desert, may, have, have, the, potential...</td>\n",
       "      <td>[blue, desert, may, potential, , , , even, , ,...</td>\n",
       "      <td>(93.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>(0.01831790433340127, 0.8910976455736771, 0.53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Checking Out' is an extraordinary film that t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>check out    extraordinary film that tower abo...</td>\n",
       "      <td>0.506007</td>\n",
       "      <td>[check, out, , , , extraordinary, film, that, ...</td>\n",
       "      <td>[check, , , , extraordinary, film, tower, film...</td>\n",
       "      <td>(40.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>(0.00787866853049517, 0.0, 1.6107920675018061,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Presque Rien' ('Come Undone') is an earlier w...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>presque Rien come Undone    early work   the i...</td>\n",
       "      <td>0.506007</td>\n",
       "      <td>[presque, rien, come, undone, , , , early, wor...</td>\n",
       "      <td>[presque, rien, come, undone, , , , early, wor...</td>\n",
       "      <td>(232.0, 0.0, 6.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>(0.04569627747687199, 0.0, 3.2215841350036123,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  label   \n",
       "0   Så som i himmelen  .. as above so below.. tha...  positive      1  \\\n",
       "1   While sporadically engrossing (including a fe...  negative      0   \n",
       "2  'Blue Desert' may have had the potential to be...  negative      0   \n",
       "3  'Checking Out' is an extraordinary film that t...  positive      1   \n",
       "4  'Presque Rien' ('Come Undone') is an earlier w...  positive      1   \n",
       "\n",
       "                                              text_c    weight   \n",
       "0     som   himmelen     above   below that very ...  0.506007  \\\n",
       "1    while sporadically engross include   few eff...  0.493993   \n",
       "2  Blue Desert may have have the potential    eve...  0.493993   \n",
       "3  check out    extraordinary film that tower abo...  0.506007   \n",
       "4  presque Rien come Undone    early work   the i...  0.506007   \n",
       "\n",
       "                                               words   \n",
       "0  [, , , som, , , himmelen, , , , , above, , , b...  \\\n",
       "1  [, , while, sporadically, engross, include, , ...   \n",
       "2  [blue, desert, may, have, have, the, potential...   \n",
       "3  [check, out, , , , extraordinary, film, that, ...   \n",
       "4  [presque, rien, come, undone, , , , early, wor...   \n",
       "\n",
       "                                            filtered   \n",
       "0  [, , , som, , , himmelen, , , , , , , special,...  \\\n",
       "1  [, , sporadically, engross, include, , , effec...   \n",
       "2  [blue, desert, may, potential, , , , even, , ,...   \n",
       "3  [check, , , , extraordinary, film, tower, film...   \n",
       "4  [presque, rien, come, undone, , , , early, wor...   \n",
       "\n",
       "                                         rawFeatures   \n",
       "0  (77.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...  \\\n",
       "1  (72.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0,...   \n",
       "2  (93.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,...   \n",
       "3  (40.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4  (232.0, 0.0, 6.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                                         featuresIDF  \n",
       "0  (0.015166436921203202, 0.0, 2.147722756669075,...  \n",
       "1  (0.014181603354891307, 0.0, 1.6107920675018061...  \n",
       "2  (0.01831790433340127, 0.8910976455736771, 0.53...  \n",
       "3  (0.00787866853049517, 0.0, 1.6107920675018061,...  \n",
       "4  (0.04569627747687199, 0.0, 3.2215841350036123,...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform\n",
    "transformed_data = data_model.transform(df)\n",
    "transformed_data.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>text_c</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>rawFeatures</th>\n",
       "      <th>featuresIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Don't Look In the Basement' is so easy to kno...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>do not look   the Basement    easy   knock but...</td>\n",
       "      <td>[do, not, look, , , the, basement, , , , easy,...</td>\n",
       "      <td>[look, , , basement, , , , easy, , , knock, tr...</td>\n",
       "      <td>(63.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0,...</td>\n",
       "      <td>(0.012408902935529893, 0.0, 0.5369306891672687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*Flat SPOILERS* &lt;br /&gt;&lt;br /&gt;Five med students,...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>flat spoiler five med student Nelson Kiefer Su...</td>\n",
       "      <td>[flat, spoiler, five, med, student, nelson, ki...</td>\n",
       "      <td>[flat, spoiler, five, med, student, nelson, ki...</td>\n",
       "      <td>(67.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0,...</td>\n",
       "      <td>(0.01319676978857941, 0.8910976455736771, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.... may seem far fetched.... but there really...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>may seem far fetched but there really be   r...</td>\n",
       "      <td>[, , may, seem, far, fetched, but, there, real...</td>\n",
       "      <td>[, , may, seem, far, fetched, really, , , real...</td>\n",
       "      <td>(69.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0,...</td>\n",
       "      <td>(0.013590703215104168, 0.0, 0.0, 0.0, 0.0, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>...Our the grandpa's hour.&lt;br /&gt;&lt;br /&gt;More tha...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>our the grandpa hourMore than the gangster its...</td>\n",
       "      <td>[our, the, grandpa, hourmore, than, the, gangs...</td>\n",
       "      <td>[grandpa, hourmore, gangster, , , detailed, de...</td>\n",
       "      <td>(36.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0,...</td>\n",
       "      <td>(0.007090801677445653, 0.0, 0.5369306891672687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>...but I regret having seen it. Since the rati...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>but   regret have see   since the rating   IMD...</td>\n",
       "      <td>[but, , , regret, have, see, , , since, the, r...</td>\n",
       "      <td>[, , regret, see, , , since, rating, , , imdb,...</td>\n",
       "      <td>(75.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0,...</td>\n",
       "      <td>(0.014772503494678443, 0.8910976455736771, 1.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  label   \n",
       "0  'Don't Look In the Basement' is so easy to kno...  positive      1  \\\n",
       "1  *Flat SPOILERS* <br /><br />Five med students,...  positive      1   \n",
       "2  .... may seem far fetched.... but there really...  negative      0   \n",
       "3  ...Our the grandpa's hour.<br /><br />More tha...  positive      1   \n",
       "4  ...but I regret having seen it. Since the rati...  negative      0   \n",
       "\n",
       "                                              text_c   \n",
       "0  do not look   the Basement    easy   knock but...  \\\n",
       "1  flat spoiler five med student Nelson Kiefer Su...   \n",
       "2    may seem far fetched but there really be   r...   \n",
       "3  our the grandpa hourMore than the gangster its...   \n",
       "4  but   regret have see   since the rating   IMD...   \n",
       "\n",
       "                                               words   \n",
       "0  [do, not, look, , , the, basement, , , , easy,...  \\\n",
       "1  [flat, spoiler, five, med, student, nelson, ki...   \n",
       "2  [, , may, seem, far, fetched, but, there, real...   \n",
       "3  [our, the, grandpa, hourmore, than, the, gangs...   \n",
       "4  [but, , , regret, have, see, , , since, the, r...   \n",
       "\n",
       "                                            filtered   \n",
       "0  [look, , , basement, , , , easy, , , knock, tr...  \\\n",
       "1  [flat, spoiler, five, med, student, nelson, ki...   \n",
       "2  [, , may, seem, far, fetched, really, , , real...   \n",
       "3  [grandpa, hourmore, gangster, , , detailed, de...   \n",
       "4  [, , regret, see, , , since, rating, , , imdb,...   \n",
       "\n",
       "                                         rawFeatures   \n",
       "0  (63.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0,...  \\\n",
       "1  (67.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0,...   \n",
       "2  (69.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0,...   \n",
       "3  (36.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0,...   \n",
       "4  (75.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0,...   \n",
       "\n",
       "                                         featuresIDF  \n",
       "0  (0.012408902935529893, 0.0, 0.5369306891672687...  \n",
       "1  (0.01319676978857941, 0.8910976455736771, 0.0,...  \n",
       "2  (0.013590703215104168, 0.0, 0.0, 0.0, 0.0, 0.6...  \n",
       "3  (0.007090801677445653, 0.0, 0.5369306891672687...  \n",
       "4  (0.014772503494678443, 0.8910976455736771, 1.0...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "transformed_test = data_model.transform(test)\n",
    "transformed_test.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tokenizer_d41190dfd02b,\n",
       " StopWordsRemover_42b3525e1430,\n",
       " CountVectorizerModel: uid=CountVectorizer_a1a420fd1f66, vocabularySize=1000,\n",
       " IDFModel: uid=IDF_fb6e03ab72e7, numDocs=10154, numFeatures=1000]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the sages of the pipeline\n",
    "data_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'movie',\n",
       " 'film',\n",
       " 'one',\n",
       " 'see',\n",
       " 'make',\n",
       " 'like',\n",
       " 'good',\n",
       " 'get',\n",
       " 'well',\n",
       " 'time',\n",
       " 'character',\n",
       " 'watch',\n",
       " 'bad',\n",
       " 'even',\n",
       " 'story',\n",
       " 'really',\n",
       " 'think',\n",
       " 'show',\n",
       " 'scene']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary of the CountVectorizer\n",
    "data_model.stages[2].vocabulary[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metics for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.mllib.evaluation import MultilabelMetrics\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "def m_metrics_l(ml_model,test_data):\n",
    "    predictions = ml_model.transform(test_data).cache()\n",
    "    predictionAndLabels = predictions.select(\"label\",\"prediction\").rdd.map(lambda x: (float(x[0]), float(x[1]))).cache()\n",
    "    \n",
    "    # Print some predictions vs labels\n",
    "    # print(predictionAndLabels.take(10))\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    \n",
    "    # Overall statistics\n",
    "    precision = metrics.precision(1.0)\n",
    "    recall = metrics.recall(1.0)\n",
    "    f1Score = metrics.fMeasure(1.0)\n",
    "    print(f\"Precision = {precision:.4f} Recall = {recall:.4f} F1 Score = {f1Score:.4f}\")\n",
    "    print(\"Confusion matrix \\n\", metrics.confusionMatrix().toArray().astype(int))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Model created in 1.11s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Spark\\spark-3.2.2-bin-hadoop3.2\\python\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.8729 Recall = 0.8356 F1 Score = 0.8539\n",
      "Confusion matrix \n",
      " [[1000  162]\n",
      " [ 219 1113]]\n",
      "Total time 7.30s.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "classifier = LogisticRegression(maxIter=10, regParam=0.1, featuresCol = \"featuresIDF\", weightCol=\"weight\")\n",
    "start = time.time()\n",
    "pipeline = Pipeline(stages=[classifier])\n",
    "print(f\"Training started.\")\n",
    "model = pipeline.fit(transformed_data)\n",
    "print(f\"Model created in {time.time()-start:.2f}s.\")\n",
    "m_metrics_l(model,transformed_test)\n",
    "print(f\"Total time {time.time()-start:.2f}s.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Model created in 4.98s.\n",
      "Precision = 0.8557 Recall = 0.6967 F1 Score = 0.7680\n",
      "Confusion matrix \n",
      " [[ 744  184]\n",
      " [ 475 1091]]\n",
      "Total time 11.64s.\n"
     ]
    }
   ],
   "source": [
    "classifier = GBTClassifier(maxIter=10, featuresCol = \"featuresIDF\", weightCol=\"weight\", maxDepth=5)\n",
    "pipeline = Pipeline(stages=[classifier])\n",
    "start = time.time()\n",
    "print(f\"Training started.\")\n",
    "model = pipeline.fit(transformed_data)\n",
    "print(f\"Model created in {time.time()-start:.2f}s.\")\n",
    "m_metrics_l(model,transformed_test)\n",
    "print(f\"Total time {time.time()-start:.2f}s.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Model created in 1.21s.\n",
      "Precision = 0.8800 Recall = 0.8317 F1 Score = 0.8552\n",
      "Confusion matrix \n",
      " [[ 992  153]\n",
      " [ 227 1122]]\n",
      "Total time 7.71s.\n"
     ]
    }
   ],
   "source": [
    "classifier = LinearSVC(maxIter=10, regParam=0.1, featuresCol = \"featuresIDF\", weightCol=\"weight\")\n",
    "pipeline = Pipeline(stages=[classifier])\n",
    "start = time.time()\n",
    "print(f\"Training started.\")\n",
    "model = pipeline.fit(transformed_data)\n",
    "print(f\"Model created in {time.time()-start:.2f}s.\")\n",
    "m_metrics_l(model,transformed_test)\n",
    "print(f\"Total time {time.time()-start:.2f}s.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Model created in 1.93s.\n",
      "Precision = 0.8682 Recall = 0.8330 F1 Score = 0.8502\n",
      "Confusion matrix \n",
      " [[ 997  168]\n",
      " [ 222 1107]]\n",
      "Total time 8.31s.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "# Multilayer Perceptron Classifier for a classification task with 1000 input features, a hidden layer with 30 nodes, and 2 output classes\n",
    "# The input layer must match the dimensionality of the input data currently = 1000\n",
    "layers = [1000, 30, 2]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "classifier = MultilayerPerceptronClassifier(maxIter=10, layers=layers,featuresCol = \"featuresIDF\", blockSize=128, seed=1234)\n",
    "pipeline = Pipeline(stages=[classifier])\n",
    "start = time.time()\n",
    "print(f\"Training started.\")\n",
    "model = pipeline.fit(transformed_data)\n",
    "print(f\"Model created in {time.time()-start:.2f}s.\")\n",
    "m_metrics_l(model,transformed_test)\n",
    "print(f\"Total time {time.time()-start:.2f}s.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Selections\n",
    "In Spark the following Feature Selectors are available\n",
    "- VectorSlicer\n",
    "- RFormula\n",
    "- ChiSqSelector\n",
    "- UnivariateFeatureSelector\n",
    "- VarianceThresholdSelector\n",
    "\n",
    "We use the ChiSqSelector to reduce the number of features from 1000 to 200. Chi-square variable selection is a technique used in statistics and machine learning to identify the most relevant features or variables in a dataset for a given classification task. It is based on the chi-square test, which is a statistical test used to determine the independence of two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text_c\", outputCol=\"words\",)\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"rawFeatures\", vocabSize=1000)\n",
    "idf = IDF(inputCol=countVectorizer.getOutputCol(), outputCol=\"featuresIDF\")\n",
    "\n",
    "# Select the top 200 features based on their chi-squared test value\n",
    "selector = ChiSqSelector(numTopFeatures=200, featuresCol=idf.getOutputCol(), outputCol=\"features\", labelCol=\"label\")\n",
    "# Crate a preprocessing pipeline with 5 stages\n",
    "pipeline_p = Pipeline(stages=[tokenizer,remover, countVectorizer, idf,selector])\n",
    "# Learn the data preprocessing model\n",
    "data_model = pipeline_p.fit(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the selected features (words) by ChiSqSelector\n",
    "To print the selected words by the ChiSqSelector in the sentiment analysis model, we can use the selectedFeatures attribute of the transformer. This attribute returns an array of the indices of the selected features, which we can map back to the original vocabulary of the CountVectorizer to get the corresponding words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie', 'make', 'like', 'good', 'get', 'watch', 'bad', 'even', 'story', 'great', 'look', 'say', 'also', 'play', 'love', 'thing', 'seem', 'life', 'want', 'plot', 'try', 'year', 'act', 'still', 'something', 'guy', 'performance', 'nothing', 'actually', 'young', 'role', 'become', 'point', 'minute', 'pretty', 'world', 'kill', 'horror', 'mean', 're', 'script', 'whole', 'least', 'may', 'acting', 'always', 'enjoy', 'family', 'live', 'series', 'anything', 'reason', 'effect', 'idea', 'fun', 'especially', 'bring', 'maybe', 'different', 'money', 'someone', 'job', 'true', 'shoot', 'waste', 'recommend', 'instead', 'hour', 'excellent', 'short', 'beautiful', 'else', 'war', 'view', 'half', 'attempt', 'poor', 'suppose', 'classic', 'human', 'stupid', 'rest', 'lack', 'either', 'completely', 'meet', 'wrong', 'dialogue', 'save', 'joke', 'awful', 'perfect', 'definitely', 'flick', 'terrible', 'fine', 'wonder', 'wonderful', 'sit', 'low', 'guess', 'experience', 'spend', 'fail', 'throw', 'win', 'relationship', 'cut', 'boring', 'favorite', 'horrible', 'rent', 'support', 'strong', 'amazing', 'heart', 'today', 'ill', 'brilliant', 'complete', 'chance', 'unfortunately', 'decent', 'simple', 'obviously', 'highly', 'silly', 'hilarious', 'crap', 'cheap', 'capture', 'god', 'dialog', 'seriously', 'none', 'zombie', 'apparently', 'ridiculous', 'annoying', 'bore', 'touch', 'avoid', 'modern', 'enjoyable', 'predictable', 'discover', 'deep', 'romantic', 'emotion', 'suck', 'bunch', 'dull', 'oscar', 'entertaining', 'mess', 'fantastic', 'premise', 'realistic', 'sorry', 'lame', 'accent', 'bother', 'dumb', 'masterpiece', 'appreciate', 'memorable', 'beauty', 'atmosphere', 'perfectly', 'unless', 'poorly', 'spoiler', 'superb', 'portrayal', 'personal', 'powerful', 'okay', 'otherwise', 'scream', 'badly', 'share', 'unique', 'fake', 'society', 'era', 'hole', 'awesome', 'flat', 'pathetic', 'plain', 'trash', 'pointless', 'rip', 'solid', 'excuse', 'complex', 'terrific', 'incredible', 'natural', 'garbage']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = data_model.stages[2].vocabulary\n",
    "selected_indexes = data_model.stages[4].selectedFeatures\n",
    "selected_words = [vocabulary[i] for i in selected_indexes]\n",
    "print(selected_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the algorithm usin the slected features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "transformed_data = data_model.transform(df)\n",
    "transformed_test = data_model.transform(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "If we use ChiSqSelector to choose the top 200 features for the sentiment analysis model, we should anticipate that the model's performance may not be as high as when we use all 1000 features. The main factor causing this outcome is the reduction of information. By selecting only the top 200 features, we may discard vital information present in the remaining 800 features, which can lead to a decline in accuracy and overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Model created in 0.94s.\n",
      "Precision = 0.8659 Recall = 0.8124 F1 Score = 0.8383\n",
      "Confusion matrix \n",
      " [[ 964  171]\n",
      " [ 255 1104]]\n",
      "Total time 6.05s.\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(maxIter=5, featuresCol = \"features\")\n",
    "start = time.time()\n",
    "pipeline = Pipeline(stages=[classifier])\n",
    "print(f\"Training started.\")\n",
    "model = pipeline.fit(transformed_data)\n",
    "print(f\"Model created in {time.time()-start:.2f}s.\")\n",
    "m_metrics_l(model,transformed_test)\n",
    "print(f\"Total time {time.time()-start:.2f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9db6cbf0fd79f8e79653fe7b0c50b956ca6e525ee712295da3c66f75e4fe96ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
