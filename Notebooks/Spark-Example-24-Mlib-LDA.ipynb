{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA topic modelling\n",
    "The notebook on LDA topic modelling for IMDB dataset using PySpark is a comprehensive guide that demonstrates how to perform topic modelling using Latent Dirichlet Allocation (LDA) in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkContext(\"local[*]\")\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some warrings, so we supress them\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                text|sentiment|\n",
      "+--------------------+---------+\n",
      "|One of the other ...| positive|\n",
      "|A wonderful littl...| positive|\n",
      "|I thought this wa...| positive|\n",
      "+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "tFile=\"data\\IMDB Dataset.csv.bz2\"\n",
    "df = spark.read.csv(tFile,header=True)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(.2, seed=100)\n",
    "#df= df.where(F.col(\"sentiment\")==\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "| positive| 5067|\n",
      "| negative| 4993|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"sentiment\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production  The filming tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Probably   all time favorite movie    story   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>sure would like   see   resurrection       d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>This show was   amazing  fresh  innovative ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The cast played Shakespeare Shakespeare lost  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0  A wonderful little production. <br /><br />The...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  The cast played Shakespeare.<br /><br />Shakes...  negative   \n",
       "\n",
       "                                              text_c  \n",
       "0    wonderful little production  The filming tec...  \n",
       "1  Probably   all time favorite movie    story   ...  \n",
       "2    sure would like   see   resurrection       d...  \n",
       "3  This show was   amazing  fresh  innovative ide...  \n",
       "4  The cast played Shakespeare Shakespeare lost  ...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove html tags from text\n",
    "df = df.withColumn(\"text_c\", F.regexp_replace(F.col(\"text\"), r'<[^>]+>', \"\"));\n",
    "# Remove non-letters\n",
    "df = df.withColumn(\"text_c\", F.regexp_replace(\"text_c\", r\"[\\.\\!\\,\\-\\']\", \" \"))\n",
    "# Remove non-letters\n",
    "df = df.withColumn(\"text_c\", F.regexp_replace(\"text_c\", r\"[^a-zA-Z\\ ]\", \"\"))\n",
    "# Remove words 1, 2 char\n",
    "df = df.withColumn(\"text_c\", F.regexp_replace(\"text_c\", r\"\\b\\w{1,2}\\b\", \" \"))\n",
    "df.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production   the film tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>probably    all time favorite movie     story ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>sure would like    see    resurrection     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>this show be    amazing   fresh   innovative i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "      <td>the cast play Shakespeare Shakespeare lose    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0  A wonderful little production. <br /><br />The...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  The cast played Shakespeare.<br /><br />Shakes...  negative   \n",
       "\n",
       "                                              text_c  \n",
       "0     wonderful little production   the film tech...  \n",
       "1  probably    all time favorite movie     story ...  \n",
       "2     sure would like    see    resurrection     ...  \n",
       "3  this show be    amazing   fresh   innovative i...  \n",
       "4  the cast play Shakespeare Shakespeare lose    ...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Define a function to apply the lemmatizer to a text\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "# Define a UDF to apply the lemmatizer to a column\n",
    "lemmatize_udf = udf(lemmatize_text, StringType())\n",
    "\n",
    "# Apply the UDF to a DataFrame column\n",
    "df = df.withColumn(\"text_c\", lemmatize_udf(df[\"text_c\"]))\n",
    "\n",
    "# Caching must be used !!!!!!\n",
    "df = df.cache()\n",
    "df.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, CountVectorizer,IDF\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessin pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"text_c\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "# Run 1 Use 500 words\n",
    "countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=500)\n",
    "# Run 2 Use 1000 words\n",
    "#countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=1000)\n",
    "# Run 3 Use Filter most frequent words\n",
    "#countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=1000,minDF=10, maxDF=5000)\n",
    "\n",
    "idf = IDF(inputCol=countVectorizer.getOutputCol(), outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[tokenizer,remover, countVectorizer,idf])\n",
    "data_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'movie', 'film', 'one', 'see', 'make', 'like', 'good', 'get', 'well', 'time', 'character', 'watch', 'bad', 'even', 'story', 'really', 'think', 'show', 'scene', 'great', 'look', 'much', 'say', 'know', 'people', 'go', 'also', 'take', 'give', 'first', 'way', 'end', 'love', 'thing', 'play', 'come', 'find', 'man', 'life', 'seem', 'work', 'actor', 'plot', 'two', 'year', 'many', 'want', 'never', 'little', 'try', 'ever', 'act', 'still', 'feel', 'back', 'part', 'use', 'something', 'old', 'real', 'funny', 'lot', 'director', 'didn', 'guy', 'woman', 'performance', 'leave', 'star', 'another', 'big', 'doesn', 'role', 'though', 'young', 'nothing', 'actually', 'start', 'tell', 'point', 'new', 'long', 'day', 'every', 'cast', 'world', 'become', 'girl', 'fact', 'turn', 'comedy', 'pretty', 'horror', 'set', 'action', 'kill', 'however', 'enough', 'around']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = data_model.stages[2].vocabulary\n",
    "print(vocabulary[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_c</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>features_c</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10055</th>\n",
       "      <td>As someone who loves baseball history, especia...</td>\n",
       "      <td>negative</td>\n",
       "      <td>someone who love baseball history   especia...</td>\n",
       "      <td>[, , , someone, who, love, baseball, history, ...</td>\n",
       "      <td>[, , , someone, love, baseball, history, , , e...</td>\n",
       "      <td>(237.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0...</td>\n",
       "      <td>(0.023557477281972106, 0.4314942162337284, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10056</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;Headlines warn us of the current c...</td>\n",
       "      <td>positive</td>\n",
       "      <td>headline warn      the current campaign    dem...</td>\n",
       "      <td>[headline, warn, , , , , , the, current, campa...</td>\n",
       "      <td>[headline, warn, , , , , , current, campaign, ...</td>\n",
       "      <td>(167.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>(0.016599572599533086, 0.0, 0.0, 0.0, 1.244164...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10057</th>\n",
       "      <td>Dog Bite Dog isn't going to be for everyone, b...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Dog Bite Dog isn    go      for everyone   but...</td>\n",
       "      <td>[dog, bite, dog, isn, , , , go, , , , , , for,...</td>\n",
       "      <td>[dog, bite, dog, isn, , , , go, , , , , , ever...</td>\n",
       "      <td>(285.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0...</td>\n",
       "      <td>(0.02832861192135886, 0.0, 1.0698027149082745,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10058</th>\n",
       "      <td>This is your typical junk comedy.&lt;br /&gt;&lt;br /&gt;T...</td>\n",
       "      <td>negative</td>\n",
       "      <td>this    your typical junk comedy there be almo...</td>\n",
       "      <td>[this, , , , your, typical, junk, comedy, ther...</td>\n",
       "      <td>[, , , typical, junk, comedy, almost, , , , la...</td>\n",
       "      <td>(132.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>(0.013120620258313578, 1.7259768649349136, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10059</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>think this movie do    down right good job ...</td>\n",
       "      <td>[, , , think, this, movie, do, , , , down, rig...</td>\n",
       "      <td>[, , , think, movie, , , , right, good, job, ,...</td>\n",
       "      <td>(204.0, 6.0, 0.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0...</td>\n",
       "      <td>(0.02027732221739371, 2.5889652974023702, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment  \\\n",
       "10055  As someone who loves baseball history, especia...  negative   \n",
       "10056  <br /><br />Headlines warn us of the current c...  positive   \n",
       "10057  Dog Bite Dog isn't going to be for everyone, b...  positive   \n",
       "10058  This is your typical junk comedy.<br /><br />T...  negative   \n",
       "10059  I thought this movie did a down right good job...  positive   \n",
       "\n",
       "                                                  text_c  \\\n",
       "10055     someone who love baseball history   especia...   \n",
       "10056  headline warn      the current campaign    dem...   \n",
       "10057  Dog Bite Dog isn    go      for everyone   but...   \n",
       "10058  this    your typical junk comedy there be almo...   \n",
       "10059     think this movie do    down right good job ...   \n",
       "\n",
       "                                                   words  \\\n",
       "10055  [, , , someone, who, love, baseball, history, ...   \n",
       "10056  [headline, warn, , , , , , the, current, campa...   \n",
       "10057  [dog, bite, dog, isn, , , , go, , , , , , for,...   \n",
       "10058  [this, , , , your, typical, junk, comedy, ther...   \n",
       "10059  [, , , think, this, movie, do, , , , down, rig...   \n",
       "\n",
       "                                                filtered  \\\n",
       "10055  [, , , someone, love, baseball, history, , , e...   \n",
       "10056  [headline, warn, , , , , , current, campaign, ...   \n",
       "10057  [dog, bite, dog, isn, , , , go, , , , , , ever...   \n",
       "10058  [, , , typical, junk, comedy, almost, , , , la...   \n",
       "10059  [, , , think, movie, , , , right, good, job, ,...   \n",
       "\n",
       "                                              features_c  \\\n",
       "10055  (237.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0...   \n",
       "10056  (167.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "10057  (285.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0...   \n",
       "10058  (132.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "10059  (204.0, 6.0, 0.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0...   \n",
       "\n",
       "                                                features  \n",
       "10055  (0.023557477281972106, 0.4314942162337284, 1.0...  \n",
       "10056  (0.016599572599533086, 0.0, 0.0, 0.0, 1.244164...  \n",
       "10057  (0.02832861192135886, 0.0, 1.0698027149082745,...  \n",
       "10058  (0.013120620258313578, 1.7259768649349136, 0.5...  \n",
       "10059  (0.02027732221739371, 2.5889652974023702, 0.0,...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data_model.transform(df)\n",
    "dataset.toPandas().tail(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA\n",
    "LDA stands for Latent Dirichlet Allocation, which is a generative statistical model used for topic modelling. Topic modelling is a technique used to discover latent topics or themes in a collection of documents or texts.\n",
    "\n",
    "The key idea behind LDA is to consider each document as a bag of words, where the order of the words does not matter. LDA uses a Bayesian approach to infer the topic distribution for each document and the word distribution for each topic.\n",
    "\n",
    "The LDA algorithm works by randomly assigning each word in a document to a topic and then iteratively updating the topic assignments based on the probabilities of each word belonging to each topic. The algorithm continues to iterate until it converges to a stable state, where the topic assignments are optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find two topics\n",
    "lda = LDA(k=2, maxIter=20)\n",
    "model = lda.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(500, 2, [42.6187, 1802.1074, 2255.5155, 1309.7856, 1054.2052, 1289.4113, 1158.5253, 1240.7307, ..., 376.7221, 295.0634, 373.723, 414.4773, 190.8515, 351.6969, 322.8845, 432.6327], 0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the LDA transformation matrix\n",
    "model.topicsMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>termIndices</th>\n",
       "      <th>termWeights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[2, 1, 13, 93, 8]</td>\n",
       "      <td>[0.008222578498306203, 0.006569659759980604, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[2, 1, 18, 33, 12]</td>\n",
       "      <td>[0.00836036856801242, 0.00785771055899993, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic         termIndices  \\\n",
       "0      0   [2, 1, 13, 93, 8]   \n",
       "1      1  [2, 1, 18, 33, 12]   \n",
       "\n",
       "                                         termWeights  \n",
       "0  [0.008222578498306203, 0.006569659759980604, 0...  \n",
       "1  [0.00836036856801242, 0.00785771055899993, 0.0...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe topics\n",
    "topics = model.describeTopics(5)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film', 'movie', 'bad', 'horror', 'get', 'book', 'story', 'character', 'one', 'woman', 'make', 'man', 'look', 'director', 'good']\n",
      "['film', 'movie', 'show', 'love', 'watch', 'see', 'like', 'good', 'funny', 'one', 'really', 'time', 'character', 'make', 'think']\n"
     ]
    }
   ],
   "source": [
    "# Print most important words per topic\n",
    "topics = model.describeTopics(15)\n",
    "for r in topics.select(\"termIndices\").collect():\n",
    "    rez = []\n",
    "    for l in r:\n",
    "        for i in l:\n",
    "            rez.append(vocabulary[i])\n",
    "    print(rez[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LDA model wiht ten topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessin pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"text_c\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "# Run 1: Use all the words\n",
    "countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=1000)\n",
    "# Run 2: Discard the very frequent words\n",
    "# countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=1000,minDF=10, maxDF=3000)\n",
    "\n",
    "idf = IDF(inputCol=countVectorizer.getOutputCol(), outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[tokenizer,remover, countVectorizer,idf])\n",
    "data_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'movie', 'film', 'one', 'see', 'make', 'like', 'good', 'get', 'well', 'time', 'character', 'watch', 'bad', 'even', 'story', 'really', 'think', 'show', 'scene', 'great', 'look', 'much', 'say', 'know', 'people', 'go', 'also', 'take', 'give', 'first', 'way', 'end', 'love', 'thing', 'play', 'come', 'find', 'man', 'life', 'seem', 'work', 'actor', 'plot', 'two', 'year', 'many', 'want', 'never', 'little', 'try', 'ever', 'act', 'still', 'feel', 'back', 'part', 'use', 'something', 'old', 'real', 'funny', 'lot', 'director', 'didn', 'guy', 'woman', 'performance', 'leave', 'star', 'another', 'big', 'doesn', 'role', 'though', 'young', 'nothing', 'actually', 'start', 'tell', 'point', 'new', 'long', 'day', 'every', 'cast', 'world', 'become', 'girl', 'fact', 'turn', 'comedy', 'pretty', 'horror', 'set', 'action', 'kill', 'however', 'enough', 'minute']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = data_model.stages[2].vocabulary\n",
    "print(vocabulary[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_c</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>features_c</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production   the film tech...</td>\n",
       "      <td>[, , , wonderful, little, production, , , the,...</td>\n",
       "      <td>[, , , wonderful, little, production, , , film...</td>\n",
       "      <td>(92.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0,...</td>\n",
       "      <td>(0.009144674725491282, 0.0, 0.5349013574541372...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>probably    all time favorite movie     story ...</td>\n",
       "      <td>[probably, , , , all, time, favorite, movie, ,...</td>\n",
       "      <td>[probably, , , , time, favorite, movie, , , , ...</td>\n",
       "      <td>(124.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0...</td>\n",
       "      <td>(0.012325431151749118, 0.8629884324674568, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>sure would like    see    resurrection     ...</td>\n",
       "      <td>[, , , sure, would, like, , , , see, , , , res...</td>\n",
       "      <td>[, , , sure, like, , , , see, , , , resurrecti...</td>\n",
       "      <td>(151.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0...</td>\n",
       "      <td>(0.015009194386404169, 0.4314942162337284, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>this show be    amazing   fresh   innovative i...</td>\n",
       "      <td>[this, show, be, , , , amazing, , , fresh, , ,...</td>\n",
       "      <td>[show, , , , amazing, , , fresh, , , innovativ...</td>\n",
       "      <td>(148.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>(0.014710998471442496, 0.0, 0.0, 0.55807637111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "      <td>the cast play Shakespeare Shakespeare lose    ...</td>\n",
       "      <td>[the, cast, play, shakespeare, shakespeare, lo...</td>\n",
       "      <td>[cast, play, shakespeare, shakespeare, lose, ,...</td>\n",
       "      <td>(99.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...</td>\n",
       "      <td>(0.009840465193735184, 0.4314942162337284, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0  A wonderful little production. <br /><br />The...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  The cast played Shakespeare.<br /><br />Shakes...  negative   \n",
       "\n",
       "                                              text_c  \\\n",
       "0     wonderful little production   the film tech...   \n",
       "1  probably    all time favorite movie     story ...   \n",
       "2     sure would like    see    resurrection     ...   \n",
       "3  this show be    amazing   fresh   innovative i...   \n",
       "4  the cast play Shakespeare Shakespeare lose    ...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [, , , wonderful, little, production, , , the,...   \n",
       "1  [probably, , , , all, time, favorite, movie, ,...   \n",
       "2  [, , , sure, would, like, , , , see, , , , res...   \n",
       "3  [this, show, be, , , , amazing, , , fresh, , ,...   \n",
       "4  [the, cast, play, shakespeare, shakespeare, lo...   \n",
       "\n",
       "                                            filtered  \\\n",
       "0  [, , , wonderful, little, production, , , film...   \n",
       "1  [probably, , , , time, favorite, movie, , , , ...   \n",
       "2  [, , , sure, like, , , , see, , , , resurrecti...   \n",
       "3  [show, , , , amazing, , , fresh, , , innovativ...   \n",
       "4  [cast, play, shakespeare, shakespeare, lose, ,...   \n",
       "\n",
       "                                          features_c  \\\n",
       "0  (92.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0,...   \n",
       "1  (124.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0...   \n",
       "2  (151.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0...   \n",
       "3  (148.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0...   \n",
       "4  (99.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...   \n",
       "\n",
       "                                            features  \n",
       "0  (0.009144674725491282, 0.0, 0.5349013574541372...  \n",
       "1  (0.012325431151749118, 0.8629884324674568, 0.0...  \n",
       "2  (0.015009194386404169, 0.4314942162337284, 0.0...  \n",
       "3  (0.014710998471442496, 0.0, 0.0, 0.55807637111...  \n",
       "4  (0.009840465193735184, 0.4314942162337284, 0.0...  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data_model.transform(df)\n",
    "dataset.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find two topics\n",
    "lda = LDA(k=10, maxIter=20)\n",
    "model = lda.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>termIndices</th>\n",
       "      <th>termWeights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[135, 423, 158, 223, 2]</td>\n",
       "      <td>[0.01669425554836518, 0.006652984717492162, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[38, 75, 215, 463, 216]</td>\n",
       "      <td>[0.006959913058347865, 0.006590408892522312, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[430, 351, 1, 942, 384]</td>\n",
       "      <td>[0.009792843428805197, 0.008521535201288306, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 18, 156, 1, 12]</td>\n",
       "      <td>[0.006819183943775015, 0.005001930988926309, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[566, 156, 504, 828, 707]</td>\n",
       "      <td>[0.01846624414614904, 0.012270222027559513, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[115, 2, 665, 20, 33]</td>\n",
       "      <td>[0.007011647844973934, 0.006653196063556585, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[88, 18, 452, 108, 187]</td>\n",
       "      <td>[0.009013184363177103, 0.007708901834386116, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[290, 112, 518, 264, 2]</td>\n",
       "      <td>[0.010307983879474753, 0.00827130795104214, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[2, 413, 850, 203, 809]</td>\n",
       "      <td>[0.008496489269192841, 0.008432247014783758, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[13, 1, 61, 2, 300]</td>\n",
       "      <td>[0.009881758450568306, 0.007700914733336307, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                termIndices  \\\n",
       "0      0    [135, 423, 158, 223, 2]   \n",
       "1      1    [38, 75, 215, 463, 216]   \n",
       "2      2    [430, 351, 1, 942, 384]   \n",
       "3      3        [2, 18, 156, 1, 12]   \n",
       "4      4  [566, 156, 504, 828, 707]   \n",
       "5      5      [115, 2, 665, 20, 33]   \n",
       "6      6    [88, 18, 452, 108, 187]   \n",
       "7      7    [290, 112, 518, 264, 2]   \n",
       "8      8    [2, 413, 850, 203, 809]   \n",
       "9      9        [13, 1, 61, 2, 300]   \n",
       "\n",
       "                                         termWeights  \n",
       "0  [0.01669425554836518, 0.006652984717492162, 0....  \n",
       "1  [0.006959913058347865, 0.006590408892522312, 0...  \n",
       "2  [0.009792843428805197, 0.008521535201288306, 0...  \n",
       "3  [0.006819183943775015, 0.005001930988926309, 0...  \n",
       "4  [0.01846624414614904, 0.012270222027559513, 0....  \n",
       "5  [0.007011647844973934, 0.006653196063556585, 0...  \n",
       "6  [0.009013184363177103, 0.007708901834386116, 0...  \n",
       "7  [0.010307983879474753, 0.00827130795104214, 0....  \n",
       "8  [0.008496489269192841, 0.008432247014783758, 0...  \n",
       "9  [0.009881758450568306, 0.007700914733336307, 0...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe topics\n",
    "topics = model.describeTopics(5)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'novel', 'read', 'house', 'film', 'character', 'movie', 'animation', 'story', 'adaptation']\n",
      "['man', 'young', 'father', 'cop', 'wife', 'woman', 'town', 'play', 'small', 'family']\n",
      "['sequel', 'evil', 'movie', 'opera', 'michael', 'production', 'hell', 'horror', 'gore', 'let']\n",
      "['film', 'show', 'episode', 'movie', 'watch', 'know', 'woman', 'comedy', 'feel', 'character']\n",
      "['zombie', 'episode', 'season', 'gay', 'party', 'bad', 'list', 'lady', 'hurt', 'annoying']\n",
      "['series', 'film', 'vampire', 'great', 'love', 'human', 'oscar', 'story', 'jack', 'character']\n",
      "['girl', 'show', 'dance', 'friend', 'short', 'cartoon', 'brother', 'boy', 'tom', 'dog']\n",
      "['game', 'music', 'match', 'song', 'film', 'movie', 'musical', 'good', 'western', 'show']\n",
      "['film', 'documentary', 'south', 'view', 'political', 'life', 'real', 'van', 'show', 'war']\n",
      "['bad', 'movie', 'funny', 'film', 'flick', 'like', 'even', 'scene', 'see', 'watch']\n"
     ]
    }
   ],
   "source": [
    "# Print most important words per topic\n",
    "topics = model.describeTopics(10)\n",
    "for r in topics.select(\"termIndices\").collect():\n",
    "    rez = []\n",
    "    for l in r:\n",
    "        for i in l:\n",
    "            rez.append(vocabulary[i])\n",
    "    print(rez[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_c</th>\n",
       "      <th>topicDistribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wonderful little production   the film tech...</td>\n",
       "      <td>[0.000795663265817789, 0.0008133383484829792, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probably    all time favorite movie     story ...</td>\n",
       "      <td>[0.4654967687392227, 0.0012263953106929593, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sure would like    see    resurrection     ...</td>\n",
       "      <td>[0.0009018104685262996, 0.16456403755126245, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this show be    amazing   fresh   innovative i...</td>\n",
       "      <td>[0.06097570247306475, 0.0006560164287984262, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the cast play Shakespeare Shakespeare lose    ...</td>\n",
       "      <td>[0.0012813788022620492, 0.0013097957148366583,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_c  \\\n",
       "0     wonderful little production   the film tech...   \n",
       "1  probably    all time favorite movie     story ...   \n",
       "2     sure would like    see    resurrection     ...   \n",
       "3  this show be    amazing   fresh   innovative i...   \n",
       "4  the cast play Shakespeare Shakespeare lose    ...   \n",
       "\n",
       "                                   topicDistribution  \n",
       "0  [0.000795663265817789, 0.0008133383484829792, ...  \n",
       "1  [0.4654967687392227, 0.0012263953106929593, 0....  \n",
       "2  [0.0009018104685262996, 0.16456403755126245, 0...  \n",
       "3  [0.06097570247306475, 0.0006560164287984262, 0...  \n",
       "4  [0.0012813788022620492, 0.0013097957148366583,...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows the result\n",
    "transformed = model.transform(dataset)\n",
    "transformed.select(\"text_c\",\"topicDistribution\").toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "@udf\n",
    "def vect_argmax(row):\n",
    "    row_arr = row.toArray()\n",
    "    max_pos = np.argmax(row_arr)\n",
    "    return(int(max_pos))\n",
    "transformed1 = transformed.withColumn(\"argmax\",vect_argmax(F.col('topicDistribution')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_c</th>\n",
       "      <th>argmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wonderful little production   the film tech...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probably    all time favorite movie     story ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sure would like    see    resurrection     ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this show be    amazing   fresh   innovative i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the cast play Shakespeare Shakespeare lose    ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_c argmax\n",
       "0     wonderful little production   the film tech...      8\n",
       "1  probably    all time favorite movie     story ...      0\n",
       "2     sure would like    see    resurrection     ...      8\n",
       "3  this show be    amazing   fresh   innovative i...      3\n",
       "4  the cast play Shakespeare Shakespeare lose    ...      9"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed1.select(\"text_c\",\"argmax\").toPandas().head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9db6cbf0fd79f8e79653fe7b0c50b956ca6e525ee712295da3c66f75e4fe96ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
